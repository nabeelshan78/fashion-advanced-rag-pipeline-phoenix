{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e14a74e-c149-4017-8dce-139307afd0e2",
   "metadata": {},
   "source": [
    "# Improving RAG System\n",
    "\n",
    "1. **Cost Measurement**: Figure out the potential costs of running a RAG application.\n",
    "2. **Prompt Improvement**: Enhance our prompts to speed up response times, while finding the right balance between time, performance, and cost.\n",
    "3. **Tracing System**: Set up a system to keep track of the inputs and outputs during interactions with the RAG system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a9a1c99-6a55-4a64-9d63-3352f1d41a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from weaviate.classes.query import Filter\n",
    "import weaviate\n",
    "import joblib\n",
    "\n",
    "from utils import (\n",
    "    ChatWidget, \n",
    "    generate_with_single_input,\n",
    "    parse_json_output,\n",
    "    get_filter_by_metadata,\n",
    "    generate_filters_from_query,\n",
    "    process_and_print_query,\n",
    "    print_properties,\n",
    "    make_url\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60551112-218d-4db8-9808-da7f97bc12f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app 'flask_app'\n",
      " * Debug mode: off\n"
     ]
    }
   ],
   "source": [
    "import flask_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13bd0c13-a873-4727-8c9c-4dfe23bcc0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate_server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b3ed13-07c9-4550-ab2a-0a30f628314f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0fbe9ab0-e7a5-49bb-b5e0-274fabdde5f7",
   "metadata": {},
   "source": [
    "## Loading the Weaviate client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c349453c-6695-402a-a62f-8dee296a0511",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = weaviate.connect_to_local(port=8079, grpc_port=50050)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c07479-73f6-46a3-8d21-366dd21d8259",
   "metadata": {},
   "source": [
    "## Preparing the Tracing with Phoenix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2829e1ee-9005-4fa5-bce9-c23b5b0c0053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import phoenix as px\n",
    "from phoenix.otel import register\n",
    "from opentelemetry.trace import Status, StatusCode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d6f62c4-0858-4176-abbc-a9094bcebcbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mFOLLOW THIS URL TO OPEN THE UI: http://rpyqcvlvppro.labs.coursera.org\u001b[0m\n",
      "üåç To view the Phoenix app in your browser, visit http://localhost:6006/\n",
      "üìñ For more information on how to use Phoenix, check out https://arize.com/docs/phoenix\n"
     ]
    }
   ],
   "source": [
    "make_url()\n",
    "session = px.launch_app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71b5e42-f663-4891-a94e-6bac640b0094",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01d22b76-d8ae-4a15-94f0-1de128a649f4",
   "metadata": {},
   "source": [
    "## Setting model cost per token\n",
    "\n",
    "we will setup in Phoenix the two models that will be used:\n",
    "\n",
    "- meta-llama/Llama-3.2-3B-Instruct-Turbo\n",
    "- meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\n",
    "\n",
    "Alongside with their cost per million of tokens. This will allow us to see the cost of each operation. \n",
    "\n",
    "**NOTE**: For illustration purposes, let's assume a cost of **1000 USD** per million tokens for `meta-llama/Llama-3.2-3B-Instruct-Turbo` and **2000 USD** for `meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo`. The real cost per token for these models is **MUCH LOWER** than this (together.ai offers 0.08 USD per million tokens for `meta-llama/Llama-3.2-3B-Instruct-Turbo`, for instance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b7604ca-1f0b-47e3-b188-a356c37b4124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mFOLLOW THIS URL TO OPEN THE UI: http://rpyqcvlvppro.labs.coursera.org/settings/models\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "make_url(\"/settings/models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a90485d-68a1-4a56-b570-7391d012afbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38cd0f6a-158a-4072-b8c9-2d99c589b54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî≠ OpenTelemetry Tracing Details üî≠\n",
      "|  Phoenix Project: chatbot\n",
      "|  Span Processor: SimpleSpanProcessor\n",
      "|  Collector Endpoint: http://127.0.0.1:6006/v1/traces\n",
      "|  Transport: HTTP + protobuf\n",
      "|  Transport Headers: {}\n",
      "|  \n",
      "|  Using a default SpanProcessor. `add_span_processor` will overwrite this default.\n",
      "|  \n",
      "|  ‚ö†Ô∏è WARNING: It is strongly advised to use a BatchSpanProcessor in production environments.\n",
      "|  \n",
      "|  `register` has set this TracerProvider as the global OpenTelemetry default.\n",
      "|  To disable this behavior, call `register` with `set_global_tracer_provider=False`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Setting up the telemetry\n",
    "phoenix_project_name = \"chatbot\"\n",
    "\n",
    "# With phoenix, we just need to register to get the tracer provider with the appropriate endpoint. \n",
    "tracer_provider_phoenix = register(project_name=phoenix_project_name, endpoint=\"http://127.0.0.1:6006/v1/traces\")\n",
    "\n",
    "# Retrieve a tracer for manual instrumentation\n",
    "tracer = tracer_provider_phoenix.get_tracer(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b30d3a6-0722-44dc-ab30-2881f59f39a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e6ef5cc-3df9-4cde-b3bb-470af7577023",
   "metadata": {},
   "source": [
    "## A Quick Recap on the Database Structure\n",
    "\n",
    "- Product database: Contains the products and their information.\n",
    "- FAQ database: Contains the FAQ data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2edc7ed-51d3-4f18-8d12-5d52ee908c92",
   "metadata": {},
   "source": [
    "### Products Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "122e233e-c12e-45e7-b4cf-f648f0bb68ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading products data\n",
    "products_data = joblib.load('dataset/clothes_json.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96ba188f-65ba-44df-824a-88cf547e9d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gender': 'Men',\n",
       " 'masterCategory': 'Apparel',\n",
       " 'subCategory': 'Topwear',\n",
       " 'articleType': 'Shirts',\n",
       " 'baseColour': 'Navy Blue',\n",
       " 'season': 'Fall',\n",
       " 'year': 2011,\n",
       " 'usage': 'Casual',\n",
       " 'productDisplayName': 'Turtle Check Men Navy Blue Shirt',\n",
       " 'price': 67.0,\n",
       " 'product_id': 15970}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's get one example\n",
    "products_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6131a5e0-0e45-4b93-be7b-bb0fd63fb0d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d29132e7-a9fe-4d9e-9e05-21ca3e08c249",
   "metadata": {},
   "source": [
    "### FAQ Database\n",
    "\n",
    "Now, let's load the FAQ database and explore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e804e76-40a6-41b5-b992-27a0b1131e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "faq = joblib.load(\"dataset/faq.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11395b26-295f-4df2-a2e4-109e121b703c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'What are your store hours?',\n",
       "  'answer': 'Our online store is open 24/7. Customer service is available from 9:00 AM to 6:00 PM, Monday through Friday.',\n",
       "  'type': 'general information'},\n",
       " {'question': 'Where is Fashion Forward Hub located?',\n",
       "  'answer': 'Fashion Forward Hub is primarily an online store. Our corporate office is located at 123 Fashion Lane, Trend City, Style State.',\n",
       "  'type': 'general information'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faq[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c30b81c-7d80-44f6-b59d-a23aeae7e03f",
   "metadata": {},
   "source": [
    "The FAQs are organized in a list, where each entry is a dictionary containing the following keys: `question`, `answer`, and `type`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdaaf5b-41e1-46b4-b45d-c4bc1829d277",
   "metadata": {},
   "source": [
    "## Recap on LLM calls and new output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6aba331d-7f01-4f9f-a71c-c140318e84c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[31mSignature:\u001b[39m\n",
       "generate_with_single_input(\n",
       "    prompt: str,\n",
       "    role: str = \u001b[33m'user'\u001b[39m,\n",
       "    top_p: float = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
       "    temperature: float = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
       "    max_tokens: int = \u001b[32m500\u001b[39m,\n",
       "    model: str = \u001b[33m'meta-llama/Llama-3.2-3B-Instruct-Turbo'\u001b[39m,\n",
       "    together_api_key=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
       "    **kwargs,\n",
       ")\n",
       "\u001b[31mDocstring:\u001b[39m <no docstring>\n",
       "\u001b[31mFile:\u001b[39m      ~/work/utils.py\n",
       "\u001b[31mType:\u001b[39m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_with_single_input?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7efa7565-10d4-432a-9b36-8a7c83e39372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"oE5e3Jc-4msxKE-98a453bcafd77ac1\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"content\": \"The primary colors are:\\n\\n1. Red\\n2. Blue\\n3. Yellow\\n\\nThese colors cannot be created by mixing other colors together, and they are the base colors used to create all other colors.\",\n",
      "        \"refusal\": null,\n",
      "        \"role\": \"assistant\",\n",
      "        \"annotations\": null,\n",
      "        \"audio\": null,\n",
      "        \"function_call\": null,\n",
      "        \"tool_calls\": []\n",
      "      },\n",
      "      \"seed\": 16019830532306369000\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1759744987,\n",
      "  \"model\": \"meta-llama/Llama-3.2-3B-Instruct-Turbo\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"service_tier\": null,\n",
      "  \"system_fingerprint\": null,\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 42,\n",
      "    \"prompt_tokens\": 41,\n",
      "    \"total_tokens\": 83,\n",
      "    \"completion_tokens_details\": null,\n",
      "    \"prompt_tokens_details\": null,\n",
      "    \"cached_tokens\": 0\n",
      "  },\n",
      "  \"prompt\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# The output is a dictionary containing the role and content from the LLM call, as well as the token usage.:\n",
    "result = generate_with_single_input(\"What are the primary colors?\")\n",
    "print(json.dumps(result, indent = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "400d691c-b585-4ae2-ba15-87e44f27d3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The primary colors are:\n",
      "\n",
      "1. Red\n",
      "2. Blue\n",
      "3. Yellow\n",
      "\n",
      "These colors cannot be created by mixing other colors together, and they are the base colors used to create all other colors.\n"
     ]
    }
   ],
   "source": [
    "print(result['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b663900-91a7-440b-87ce-791e058b5c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83\n"
     ]
    }
   ],
   "source": [
    "print(result['usage']['total_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3703dd4f-5457-4356-9c01-c5af560bfb23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e8252db-a533-4d8f-822d-1e9c39737d38",
   "metadata": {},
   "source": [
    "## Function to generate the parameters dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c86939f9-b22e-47c9-8061-0bd34f24708e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_params_dict(\n",
    "    prompt: str,\n",
    "    temperature: float = 1.0,\n",
    "    role: str = 'user',\n",
    "    top_p: float = 1.0,\n",
    "    max_tokens: int = 500,\n",
    "    model: str = \"meta-llama/Llama-3.2-3B-Instruct-Turbo\"\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Generates a dictionary of parameters for calling a Language Learning Model (LLM),\n",
    "    allowing for the customization of several key options that can affect the output from the model. \n",
    "\n",
    "    Args:\n",
    "        prompt (str): The input text that will be provided to the model to guide text generation.\n",
    "        temperature (float): A value between 0 and 1 that controls the randomness of the model's output; \n",
    "            lower values result in more repetitive and deterministic results, while higher values enhance randomness.\n",
    "        role (str): The role designation to be used in context, typically identifying the initiator of the interaction.\n",
    "        top_p (float): A value between 0 and 1 that manages diversity through the technique of nucleus sampling; \n",
    "            this parameter limits the set of considered words to the smallest possible while maintaining 'top_p' cumulative probability.\n",
    "        max_tokens (int): The maximum number of tokens that the model is allowed to generate in response, where a token can \n",
    "            be as short as one character or as long as one word.\n",
    "        model (str): The specific model identifier to be utilized for processing the request. This typically specifies both \n",
    "            the version and configuration of the LLM to be employed.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing all specified parameters which can then be used to configure and execute a call to the LLM.\n",
    "    \"\"\"\n",
    "    # Create the dictionary with the necessary parameters\n",
    "    kwargs = {\n",
    "        \"prompt\": prompt,\n",
    "        \"role\": role,\n",
    "        \"temperature\": temperature,\n",
    "        \"top_p\": top_p,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"model\": model\n",
    "    }\n",
    "    return kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a3c3c62-5b50-41ea-ab76-9a083e6a72f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt': 'Solve 3x^2 + 5 = 0', 'role': 'user', 'temperature': 1.0, 'top_p': 1.0, 'max_tokens': 500, 'model': 'meta-llama/Llama-3.2-3B-Instruct-Turbo'}\n"
     ]
    }
   ],
   "source": [
    "kwargs = generate_params_dict(\"Solve 3x^2 + 5 = 0\")\n",
    "print(kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c27a09b-c39f-443a-9e1a-f3a539d85a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content: To solve the quadratic equation 3x^2 + 5 = 0, we can use the quadratic formula:\n",
      "\n",
      "x = (-b ¬± ‚àö(b^2 - 4ac)) / 2a\n",
      "\n",
      "In this case, a = 3, b = 0, and c = 5. \n",
      "\n",
      "Plugging these values into the formula, we get:\n",
      "\n",
      "x = (-(0) ¬± ‚àö((0)^2 - 4(3)(5))) / 2(3)\n",
      "x = (0 ¬± ‚àö(0 - 60)) / 6\n",
      "x = (0 ¬± ‚àö(-60)) / 6\n",
      "\n",
      "Unfortunately, there is no real solution to this equation, as the square root of a negative number is not a real number. However, we can express the solution using imaginary numbers:\n",
      "\n",
      "x = (0 ¬± ‚àö(-60)) / 6\n",
      "x = (0 ¬± i‚àö60) / 6\n",
      "\n",
      "Simplifying further, we get:\n",
      "\n",
      "x = (0 ¬± i‚àö(4*15)) / 6\n",
      "x = (0 ¬± i2‚àö15) / 6\n",
      "x = (0 ¬± i‚àö15) / 3\n",
      "\n",
      "So, the two solutions to the equation are:\n",
      "\n",
      "x = (0 + i‚àö15) / 3\n",
      "x = (0 - i‚àö15) / 3\n",
      "\n",
      "Total Tokens: 328\n"
     ]
    }
   ],
   "source": [
    "result = generate_with_single_input(**kwargs)\n",
    "content = result['choices'][0]['message']['content']\n",
    "total_tokens = result['usage']['total_tokens']\n",
    "print(f\"Content: {content}\\n\\nTotal Tokens: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f28347-1a1f-4b62-8b09-d5f75242421e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27f1fb01-c69d-4e33-bc27-34e3afdb0bf0",
   "metadata": {},
   "source": [
    "## Improving Task handling\n",
    "\n",
    "### Refactoring the function to decide whether it is an FAQ or product-related question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc2179f9-2eb8-40ba-b037-448009c77766",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_faq_or_product(query, simplified = False):\n",
    "    \"\"\"\n",
    "    Determines whether a given instruction prompt is related to a frequently asked question (FAQ) or a product inquiry.\n",
    "\n",
    "    Parameters:\n",
    "    - query (str): The instruction or query that needs to be labeled as either FAQ or Product related.\n",
    "    - simplified (bool): If True, uses a simplified prompt.\n",
    "\n",
    "    Returns:\n",
    "    - str: The label 'FAQ' if the prompt is deemed a frequently asked question, 'Product' if it is related to product information, or\n",
    "      None if the label is inconclusive.\n",
    "    \"\"\"\n",
    " \n",
    "    # If not simplified, uses a more complex prompt\n",
    "    if not simplified:\n",
    "        PROMPT = f\"\"\"\n",
    "You are a text classification assistant. \n",
    "Your task is to label the following instruction as either 'FAQ' or 'Product'. \n",
    "\n",
    "Definitions:\n",
    "- Product: Queries that ask about specific clothes, their features, prices, colors, availability, or details related to purchasing products.\n",
    "- FAQ: Queries that ask about store policies, refunds, returns, shipping, sizing help, or other general information not tied to a specific product.\n",
    "\n",
    "Examples:\n",
    "1. \"Is there a refund for incorrectly bought clothes?\": FAQ\n",
    "2. \"Tell me about the cheapest T-shirts that you have.\": Product\n",
    "3. \"Do you have blue T-shirts under 100 dollars?\": Product\n",
    "4. \"I bought a T-shirt and I didn't like it. How can I get a refund?\": FAQ\n",
    "5. \"What sizes are available in jackets?\": Product\n",
    "6. \"How long does shipping usually take?\": FAQ\n",
    "\n",
    "Instructions:\n",
    "- Return only ONE word: either 'FAQ' or 'Product'.\n",
    "- Do not include explanations, punctuation, or extra words.\n",
    "\n",
    "Instruction: {query}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "    # If simlpified, uses a simplified prompt.\n",
    "    else:\n",
    "        PROMPT = f\"\"\"\n",
    "Classify the query as FAQ or Product for a clothing store.\n",
    "Product = asks about product details, availability, or outfit suggestions.\n",
    "FAQ = asks about store policies, refunds, or general info.\n",
    "Examples:\n",
    "- \"What colors do your hoodies come in?\": Product\n",
    "- \"How can I exchange a shirt?\": FAQ\n",
    "- \"Suggest an outfit for a beach picnic\": Product\n",
    "Query: {query}\n",
    "Return only: FAQ or Product.\n",
    "\"\"\"\n",
    "        \n",
    "    with tracer.start_as_current_span(\"routing_faq_or_product\", openinference_span_kind = 'tool') as span:\n",
    "        span.set_input(str({\"query\":query, \"simplified\": simplified}))\n",
    "        \n",
    "        # Get the kwargs dictinary to call the llm, with PROMPT as prompt, low temperature (0 or near 0) and max_tokens = 10\n",
    "        kwargs = generate_params_dict(PROMPT, temperature = 0, max_tokens = 10)\n",
    "\n",
    "        # Call generate_with_single_input with **kwargs\n",
    "        with tracer.start_as_current_span(\"router_call\", openinference_span_kind = 'llm') as router_span:\n",
    "            router_span.set_input(kwargs)\n",
    "            try:\n",
    "                response = generate_with_single_input(**kwargs) \n",
    "            except Exception as error:\n",
    "                router_span.record_exception(error)\n",
    "                router_span.set_status(Status(StatusCode.ERROR))\n",
    "            else:\n",
    "                # OpenInference Semantic Conventions for computing Costs\n",
    "                router_span.set_attribute(\"llm.token_count.prompt\", response['usage']['prompt_tokens'])\n",
    "                router_span.set_attribute(\"llm.token_count.completion\", response['usage']['completion_tokens'])\n",
    "                router_span.set_attribute(\"llm.token_count.total\", response['usage']['total_tokens'])\n",
    "                router_span.set_attribute(\"llm.model_name\", response['model'])\n",
    "                router_span.set_attribute(\"llm.provider\", 'together.ai')\n",
    "                router_span.set_output(response)\n",
    "                router_span.set_status(Status(StatusCode.OK))\n",
    "        \n",
    "    \n",
    "        # Get the Label by accessing the content key of the response dictionary\n",
    "        label = response['choices'][0]['message']['content']\n",
    "        total_tokens = response['usage']['total_tokens']\n",
    "        span.set_output(str({\"label\": label, 'total_tokens':total_tokens}))\n",
    "        span.set_status(Status(StatusCode.OK))\n",
    "\n",
    "        # Improvement to prevent cases where LLM outputs more than one word\n",
    "        if 'faq' in label.lower():\n",
    "            label = 'FAQ'\n",
    "        elif 'product' in label.lower():\n",
    "            label = 'Product'\n",
    "        else:\n",
    "            label = 'undefined'\n",
    "    \n",
    "        return label, total_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d82fd85-ba80-49fd-900e-bf2faa8a4368",
   "metadata": {},
   "source": [
    "Let's test both versions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d35e4d06-1f56-4bde-86c4-9ccbb8be2036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is your return policy?\n",
      "  Standard    ‚Üí Label: \u001b[32mFAQ\u001b[0m | Tokens: \u001b[31m261\u001b[0m\n",
      "  Simplified  ‚Üí Label: \u001b[32mFAQ\u001b[0m | Tokens: \u001b[32m132\u001b[0m\n",
      "\n",
      "Query: Give me three examples of blue T-shirts you have available.\n",
      "  Standard    ‚Üí Label: \u001b[32mProduct\u001b[0m | Tokens: \u001b[31m267\u001b[0m\n",
      "  Simplified  ‚Üí Label: \u001b[32mProduct\u001b[0m | Tokens: \u001b[32m138\u001b[0m\n",
      "\n",
      "Query: How can I contact the user support?\n",
      "  Standard    ‚Üí Label: \u001b[32mFAQ\u001b[0m | Tokens: \u001b[31m263\u001b[0m\n",
      "  Simplified  ‚Üí Label: \u001b[32mFAQ\u001b[0m | Tokens: \u001b[32m134\u001b[0m\n",
      "\n",
      "Query: Do you have blue Dresses?\n",
      "  Standard    ‚Üí Label: \u001b[32mProduct\u001b[0m | Tokens: \u001b[31m261\u001b[0m\n",
      "  Simplified  ‚Üí Label: \u001b[32mProduct\u001b[0m | Tokens: \u001b[32m132\u001b[0m\n",
      "\n",
      "Query: Create a look suitable for a wedding party happening during dawn.\n",
      "  Standard    ‚Üí Label: \u001b[32mProduct\u001b[0m | Tokens: \u001b[31m267\u001b[0m\n",
      "  Simplified  ‚Üí Label: \u001b[32mProduct\u001b[0m | Tokens: \u001b[32m138\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "    'What is your return policy?', \n",
    "    'Give me three examples of blue T-shirts you have available.', \n",
    "    'How can I contact the user support?', \n",
    "    'Do you have blue Dresses?',\n",
    "    'Create a look suitable for a wedding party happening during dawn.'\n",
    "]\n",
    "\n",
    "labels = ['FAQ', 'Product', 'FAQ', 'Product', 'Product']\n",
    "\n",
    "for query, correct_label in zip(queries, labels):\n",
    "    # Call check_if_faq_or_product and store the results\n",
    "    response_std, tokens_std = check_if_faq_or_product(query, simplified=False)\n",
    "    response_simp, tokens_simp = check_if_faq_or_product(query, simplified=True)\n",
    "    \n",
    "    # Print results\n",
    "    process_and_print_query(query, correct_label, response_std, tokens_std, response_simp, tokens_simp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f62b03-3466-40aa-81a2-716a2c7dab6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73224ca6-8567-4e98-b34b-e4ccb7fd18ba",
   "metadata": {},
   "source": [
    "### Answering a FAQ question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8499e32-bdb2-4378-9f42-357aa417abb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tracer.tool\n",
    "def generate_faq_layout(faq_dict):\n",
    "    \"\"\"\n",
    "    Generates a formatted string layout for a list of FAQs.\n",
    "\n",
    "    Returns:\n",
    "    - str: A string representing the formatted layout of FAQs, with each entry on a separate line.\n",
    "    \"\"\"\n",
    "\n",
    "    t = \"\"\n",
    "    \n",
    "    # Iterate over every FAQ question in the FAQ list\n",
    "    for f in faq_dict:\n",
    "        t += f\"Question: {f['question']} Answer: {f['answer']} Type: {f['type']}\\n\" \n",
    "\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19511af2-cb37-4736-a50e-033c53eb2c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What are your store hours? Answer: Our online store is open 24/7. Customer service is available from 9:00 AM to 6:00 PM, Monday through Friday. Type: general information\n",
      "Question: Where is Fashion Forward Hub located? Answer: Fashion Forward Hub is primarily an online store. Our corporate office is located at 123 Fashion Lane, Trend City, Style State. Type: general information\n",
      "Question: Do you have a physical store location? Answer: At this time, we operate exclusively online. This allows us to offer a broader selection and lower prices directly to you. Type: general information\n",
      "Question: How can I create an account with Fashion Forward Hub? Answer: Click on 'Sign Up' in the top right corner of our website and follow the instructions to set up your account. Type: general information\n",
      "Question: How do I subscribe to your newsletter? Answer: To receive the latest updates and promotions, sign up for our newsletter at the bottom of our homepage. Type: general information\n",
      "Question:\n"
     ]
    }
   ],
   "source": [
    "faq_layout = generate_faq_layout(faq)\n",
    "print(faq_layout[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dda5ca5f-a755-457e-bf36-b8613fc44d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Where is Fashion Forward Hub located? Answer: Fashion Forward Hub is primarily an online store. Our corporate office is located at 123 Fashion Lane, Trend City, Style State. Type: general information\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(generate_faq_layout(faq[1:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf67ec2e-dc42-4994-bfa9-46aaca37f44e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5bc0fd86-7406-45e2-b420-b5d286f9711a",
   "metadata": {},
   "source": [
    "### Querying on FAQ\n",
    "\n",
    "Previously, the entire FAQ was added in the query. This approach is useful to provide the entire information to the LLM, but it significantly increases token usage and execution time. Now that we are refining our chatbot, it's time to use a more efficient collection to handle it! Let's load the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c26e53de-a82d-4994-94ae-02abd9a39344",
   "metadata": {},
   "outputs": [],
   "source": [
    "faq_collection = client.collections.get(\"Faq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28d34df-92f8-4baa-9a79-f5e15e69e3bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "This code:\n",
    "\n",
    "    Retrieves the FAQ collection from Weaviate.\n",
    "    Loops over the FAQ dataset.\n",
    "    Generates a deterministic UUID for each FAQ entry.\n",
    "    Adds entries in batches of 20 and 5 concurrent requests.\n",
    "    Uses a progress bar (tqdm) to track insertion progress.\n",
    "\n",
    "Effect: Efficiently uploads our FAQ data into Weaviate so it can be queried later by vector similarity in our RAG pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc4108ac-ca10-490b-800d-b2d3a6b67eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 26797.24it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from weaviate.util import generate_uuid5\n",
    "\n",
    "# Set up a batch process with specified fixed size and concurrency\n",
    "with faq_collection.batch.fixed_size(batch_size=20, concurrent_requests=5) as batch:\n",
    "    # Iterate over a subset of the dataset\n",
    "    for document in tqdm(faq):\n",
    "        # Generate a UUID based on the chunk text for unique identification\n",
    "        uuid = generate_uuid5(document['question'])\n",
    "\n",
    "        # Add the chunk object to the batch with properties and UUID\n",
    "        batch.add_object(\n",
    "            properties=document,\n",
    "            uuid=uuid,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c265aa2d-0bd6-4fea-ab13-2124d01eef79",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = faq_collection.query.near_text(\"What is the return policy?\", limit = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a7fa36b7-e299-4b6b-9d05-a0a324d321a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"answer\": \"We accept returns within 30 days of delivery. Conditions apply for specific categories like accessories.\",\n",
      "  \"question\": \"What is your return policy timeframe?\",\n",
      "  \"type\": \"returns and exchanges\"\n",
      "}\n",
      "--------------------------------------------------\n",
      "{\n",
      "  \"answer\": \"Sale items are final sale and cannot be returned or exchanged, unless stated otherwise.\",\n",
      "  \"question\": \"Can I return a sale item?\",\n",
      "  \"type\": \"returns and exchanges\"\n",
      "}\n",
      "--------------------------------------------------\n",
      "{\n",
      "  \"answer\": \"Return processing typically takes 5-7 business days from when the item is received at our warehouse.\",\n",
      "  \"question\": \"How long does it take to process a return?\",\n",
      "  \"type\": \"returns and exchanges\"\n",
      "}\n",
      "--------------------------------------------------\n",
      "{\n",
      "  \"answer\": \"We provide a prepaid return label for domestic returns. For international returns, shipping is at the customer's cost.\",\n",
      "  \"question\": \"Are return shipping costs covered?\",\n",
      "  \"type\": \"returns and exchanges\"\n",
      "}\n",
      "--------------------------------------------------\n",
      "{\n",
      "  \"answer\": \"Initiate an exchange through our Returns Center, selecting the item you wish to exchange and the desired replacement.\",\n",
      "  \"question\": \"How do I exchange an item?\",\n",
      "  \"type\": \"returns and exchanges\"\n",
      "}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for obj in res.objects:\n",
    "    print_properties(obj)\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d0855c-0b25-444c-8838-4a6d2160aaeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "553073a2-d998-4e7e-8583-1856d4be718b",
   "metadata": {},
   "source": [
    "Below is the function used to answer a FAQ question.\n",
    "**It will only run if the question is already labeled as a FAQ.**\n",
    "we‚Äôve seen this question in a previous version, but now there‚Äôs one change:\n",
    "\n",
    "1. A new parameter called `simplified` was added.\n",
    "   This controls whether the function uses the full `faq` list or a smaller selection from it.\n",
    "   If `simplified` is `True`, we should run a semantic search on the FAQ collection and use only the top 5 results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8abca56e-1736-40b1-951a-ebe2aa502a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_on_faq(query, simplified = False, **kwargs):\n",
    "    \"\"\"\n",
    "    Constructs a prompt to query an FAQ system and generates a response.\n",
    "\n",
    "    This function integrates an FAQ layout into the prompt to help generate a suitable answer to the given query\n",
    "    using a language model. It supports additional keyword arguments to customize the prompt generation process.\n",
    "\n",
    "    Parameters:\n",
    "    - query (str): The query about which the function seeks to provide an answer from the FAQ.\n",
    "    - simplified (bool): If True, uses semantic search to extract a relevant subset of FAQ questions\n",
    "    - **kwargs: Optional keyword arguments for extra configuration of prompt parameters.\n",
    "\n",
    "    Returns:\n",
    "    - str: The response generated from the language model based on the input query and FAQ layout.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # If not simplified, generate the faq layout with the entire FAQ questions\n",
    "    if not simplified:\n",
    "        # Set the tracer as a chain type, since in non-simplified version, the full FAQ is used\n",
    "        with tracer.start_as_current_span(\"query_on_faq\", openinference_span_kind=\"tool\") as span:\n",
    "            \n",
    "            span.set_input({\"query\": query, \"simplified\": simplified})\n",
    "            faq_layout = generate_faq_layout(faq)\n",
    "            \n",
    "            # Generate the prompt\n",
    "            PROMPT = f\"\"\"\n",
    "You are an assistant that answers customer questions using only the provided FAQ content. \n",
    "\n",
    "Instructions:\n",
    "- Use only the information from the FAQ to answer the question.\n",
    "- If multiple FAQ entries are relevant, combine them into a single helpful answer.\n",
    "- Do not mention the FAQ or that the answer is coming from an FAQ.\n",
    "- Be clear and concise, but cover all relevant details.\n",
    "\n",
    "<FAQ>\n",
    "{faq_layout}\n",
    "</FAQ>\n",
    "\n",
    "Question: {query}\n",
    "Answer:\n",
    "\"\"\" \n",
    "            span.set_attribute(\"prompt\", PROMPT)\n",
    "\n",
    "            # Generate the parameters dict with PROMPT and **kwargs \n",
    "            kwargs = generate_params_dict(PROMPT, **kwargs) \n",
    "\n",
    "            span.set_attribute(\"output\", str(kwargs))\n",
    "            span.set_status(Status(StatusCode.OK))\n",
    "    \n",
    "            return kwargs\n",
    "    \n",
    "    else:\n",
    "        with tracer.start_as_current_span(\"query_on_faq\", openinference_span_kind=\"tool\") as span:\n",
    "            span.set_input({\"query\": query, \"simplified\": simplified})\n",
    "            with tracer.start_as_current_span(\"retrieve_faq_questions\", openinference_span_kind=\"retriever\") as retrieve_span:\n",
    "                \n",
    "                # Get the 5 most relevant FAQ objects, in this case limit = 5\n",
    "                results = faq_collection.query.near_text(query, limit=5)\n",
    "\n",
    "                # Set the retrieved documents as attributes on the span\n",
    "                for i, document in enumerate(results.objects): \n",
    "                    retrieve_span.set_attribute(f\"retrieval.documents.{i}.document.id\", str(document.uuid)) \n",
    "                    retrieve_span.set_attribute(f\"retrieval.documents.{i}.document.metadata\", str(document.metadata)) \n",
    "                    retrieve_span.set_attribute( \n",
    "                        f\"retrieval.documents.{i}.document.content\", str(document.properties) \n",
    "                    )  \n",
    "                # Transform the results in a list of dictionary\n",
    "                results = [x.properties for x in results.objects] \n",
    "                # Generate the faq layout with the new list of FAQ questions `results`\n",
    "                faq_layout = generate_faq_layout(results) \n",
    "\n",
    "            # Different prompt to deal with this new scenario. \n",
    "            PROMPT = (\n",
    "    f\"Answer the following query for a clothing store using the relevant FAQ provided. \"\n",
    "    f\"The FAQs are ordered by relevance, most relevant first. Use one or more FAQ items as needed. \"\n",
    "    f\"Answer only the question; do not mention the FAQ.\\n\"\n",
    "    f\"<FAQ>\\n\"\n",
    "    f\"{faq_layout}\\n\"\n",
    "    f\"</FAQ>\\n\"\n",
    "    f\"Query: {query}\"\n",
    ")\n",
    "\n",
    "            span.set_attribute(\"prompt\", PROMPT)\n",
    "        \n",
    "            # Generate the parameters dict with PROMPT and **kwargs \n",
    "            kwargs = generate_params_dict(PROMPT, **kwargs) \n",
    "        \n",
    "            span.set_attribute(\"output\", str(kwargs))\n",
    "            span.set_status(Status(StatusCode.OK))\n",
    "    \n",
    "            return kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a72d9a8-5e77-43bd-9ada-959e8df8a097",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "477dfc56-e6bd-473d-92a5-be3232dbbeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dictionary of arguments\n",
    "kwargs = query_on_faq(\"I received the dress I ordered but I don't like it. How can I return it?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9c892958-9eba-4acc-a0ce-2ced509e6189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "808\n"
     ]
    }
   ],
   "source": [
    "# The number of split tokens in this prompt is:\n",
    "print(len(kwargs['prompt'].split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "406c15b2-d53d-45f2-bfe2-a368ac4aca0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the inference\n",
    "result = generate_with_single_input(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd87c6b-941e-4334-a175-9fb7c8e1cb44",
   "metadata": {},
   "source": [
    "Let's check the content without the simplified version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fbee08d2-9805-4239-91a0-12afe12778bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To initiate a return, please visit our Returns Center and select the dress you wish to exchange. Once in the Returns Center, follow the prompted steps and print a prepaid return label for your domestic return. For international returns, please arrange for shipping at your own cost.\n",
      "\n",
      "Please note that the return window is within 30 days of delivery. Refunds are issued within 5-7 business days after receiving the returned item at our warehouse. Sale items are final and cannot be returned or exchanged, unless stated otherwise.\n"
     ]
    }
   ],
   "source": [
    "print(result['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "37157c38-0738-4105-9b5d-2a0e834ea6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1173\n"
     ]
    }
   ],
   "source": [
    "# Get the total tokens\n",
    "print(result['usage']['total_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb32d7ca-bce3-4fe7-8db6-c585f2775eb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15375300-4d7f-4a83-aa4b-7c51beed00ea",
   "metadata": {},
   "source": [
    "Now let's check the simplified version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "95516fe9-88bc-4e71-afaa-6adfa65b2db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dictionary of arguments\n",
    "kwargs = query_on_faq(\"I received the dress I ordered but I don't like it. How can I return it?\", simplified = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b33c19d4-3bd6-4199-a6b2-93422112fdb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201\n"
     ]
    }
   ],
   "source": [
    "# The number of split tokens in this prompt is:\n",
    "print(len(kwargs['prompt'].split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2ce5b925-26d2-4db2-a259-8bdeb8b7f1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the inference\n",
    "result = generate_with_single_input(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6b828248-bab3-4479-a699-1aff7356c8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can initiate a return through our Returns Center, selecting the dress you wish to return and the desired replacement.\n"
     ]
    }
   ],
   "source": [
    "print(result['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a6d80a3c-11bb-44ac-8522-1b7ef9bd8301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314\n"
     ]
    }
   ],
   "source": [
    "# Get the total tokens\n",
    "print(result['usage']['total_tokens'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17639a0-95b7-40df-b9f9-746121daecf7",
   "metadata": {},
   "source": [
    "    Note that the answer is still correct and the final token count is way smaller!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83de7e43-25f3-4e31-914c-83a5002df755",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d04f32a-484f-463c-9706-8c5a8e8bb546",
   "metadata": {},
   "source": [
    "## Improving the Decision Between Creative or Technical Product Queries\n",
    "\n",
    "The goal is the same: reduce token usage while keeping good accuracy.\n",
    "\n",
    "1. It now returns the total number of tokens used during processing.\n",
    "2. It includes a new argument called `simplified`.\n",
    "\n",
    "Must meet both of the following conditions:\n",
    "\n",
    "* Accuracy of at least **80%** on the test set (we can get **at most one** question wrong).\n",
    "* Use **fewer than 170 tokens** for **every** query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f7ede345-a521-4291-9833-176014bd272d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_task_nature(query, simplified = True):\n",
    "    \"\"\"\n",
    "    Determines the nature of a query, labeling it as either creative or technical.\n",
    "\n",
    "    This function constructs a prompt for a language model to decide if a given query requires a creative response,\n",
    "    such as making suggestions or composing ideas, or a technical response, like providing product details or prices.\n",
    "\n",
    "    Parameters:\n",
    "    - query (str): The query to be evaluated for its nature.\n",
    "    - simplified (bool): If True, uses a simplified prompt.\n",
    "\n",
    "    Returns:\n",
    "    - str: The label 'creative' if the query requires creative input, or 'technical' if it requires technical information.\n",
    "    \"\"\"\n",
    "    \n",
    "    if not simplified:\n",
    "        PROMPT = f\"\"\"\n",
    "Decide if the following query is a query that requires creativity (creating, composing, making new things) \n",
    "or technical (information about products, availability, descriptions, or prices). \n",
    "\n",
    "Definitions:\n",
    "- Creative: requires imagination or styling advice (e.g., suggesting looks, composing outfits, matching accessories).\n",
    "- Technical: requests factual product information (availability, price, catalog items, counts, colors, sizes).\n",
    "\n",
    "Label it strictly as either \"creative\" or \"technical\".\n",
    "\n",
    "Examples:\n",
    "- \"Give me suggestions on a nice look for a nightclub.\" ‚Üí creative\n",
    "- \"What are the blue dresses you have available?\" ‚Üí technical\n",
    "- \"Give me three T-shirts for summer.\" ‚Üí technical\n",
    "- \"Give me a look for attending a wedding party.\" ‚Üí creative\n",
    "- \"Suggest a stylish outfit for visiting a museum.\" ‚Üí creative\n",
    "- \"Do you have red jackets under 50 dollars?\" ‚Üí technical\n",
    "\n",
    "Query to be analyzed: {query}\n",
    "\n",
    "Only output one word: \"creative\" or \"technical\".\n",
    "\"\"\"\n",
    "\n",
    "    # If simplified, uses a simplified query\n",
    "    else:\n",
    "        PROMPT = f\"\"\"\n",
    "Decide if the query requires creative input (ideas, styling, outfit suggestions) \n",
    "or technical info (product details, prices, availability). \n",
    "Examples:\n",
    "- \"Suggest an outfit for a beach party\": creative\n",
    "- \"Which blue dresses are in stock?\": technical\n",
    "- \"Give a summer T-shirt combination\": creative\n",
    "- \"List the sizes available for red jackets\": technical\n",
    "Query: {query}\n",
    "Use only one word: creative or technical.\n",
    "\"\"\"\n",
    "    \n",
    "    with tracer.start_as_current_span(\"decide_task_nature\", openinference_span_kind=\"tool\") as span:\n",
    "    # Generate the kwards dictionary by passing the PROMPT, low temperature and max_tokens = 1\n",
    "        span.set_input({\"query\":query, \"simplified\": simplified})\n",
    "        kwargs = generate_params_dict(PROMPT, temperature = 0, max_tokens = 1)\n",
    "\n",
    "        with tracer.start_as_current_span(\"router_call\", openinference_span_kind = 'llm') as router_span:\n",
    "            router_span.set_input(kwargs)\n",
    "            try:\n",
    "                response = generate_with_single_input(**kwargs) \n",
    "            except Exception as error:\n",
    "                router_span.record_exception(error)\n",
    "                router_span.set_status(Status(StatusCode.ERROR))\n",
    "            else:\n",
    "                # OpenInference Semantic Conventions for computing Costs\n",
    "                router_span.set_attribute(\"llm.token_count.prompt\", response['usage']['prompt_tokens'])\n",
    "                router_span.set_attribute(\"llm.token_count.completion\", response['usage']['completion_tokens'])\n",
    "                router_span.set_attribute(\"llm.token_count.total\", response['usage']['total_tokens'])\n",
    "                router_span.set_attribute(\"llm.model_name\", response['model'])\n",
    "                router_span.set_attribute(\"llm.provider\", 'together.ai')\n",
    "                router_span.set_output(response)\n",
    "                router_span.set_status(Status(StatusCode.OK))\n",
    "\n",
    "        # Get the Label by accessing the content key of the response dictionary\n",
    "        label = response['choices'][0]['message']['content']\n",
    "        total_tokens = response['usage']['total_tokens']\n",
    "        span.set_output(str({\"label\": label, 'total_tokens':total_tokens}))\n",
    "        span.set_status(Status(StatusCode.OK))    \n",
    "    \n",
    "        return label, total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad5170a-c303-4e15-9550-66f827e5a195",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "00299937-96d2-4834-ad26-4bf0a7c2ddda",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\"Give me two sneakers with vibrant colors.\",\n",
    "           \"What are the most expensive clothes you have in your catalogue?\",\n",
    "           \"I have a green Dress and I like a suggestion on an accessory to match with it.\",\n",
    "           \"Give me three trousers with vibrant colors you have in your catalogue.\",\n",
    "           \"Create a look for a woman walking in a park on a sunny day. It must be fresh due to hot weather.\"\n",
    "           ]\n",
    "\n",
    "labels = ['technical', 'technical', 'creative', 'technical', 'creative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3cb1452b-940b-4a3d-9f28-5ef166ab2c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Give me two sneakers with vibrant colors. Label Predicted: \u001b[31mcreative\u001b[0m. Correct Label: technical Total Tokens: \u001b[32m134\u001b[0m\n",
      "======================================================================\n",
      "Query: What are the most expensive clothes you have in your catalogue? Label Predicted: \u001b[32mtechnical\u001b[0m. Correct Label: technical Total Tokens: \u001b[32m138\u001b[0m\n",
      "======================================================================\n",
      "Query: I have a green Dress and I like a suggestion on an accessory to match with it. Label Predicted: \u001b[32mcreative\u001b[0m. Correct Label: creative Total Tokens: \u001b[32m144\u001b[0m\n",
      "======================================================================\n",
      "Query: Give me three trousers with vibrant colors you have in your catalogue. Label Predicted: \u001b[32mtechnical\u001b[0m. Correct Label: technical Total Tokens: \u001b[32m139\u001b[0m\n",
      "======================================================================\n",
      "Query: Create a look for a woman walking in a park on a sunny day. It must be fresh due to hot weather. Label Predicted: \u001b[32mcreative\u001b[0m. Correct Label: creative Total Tokens: \u001b[32m150\u001b[0m\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "for query, correct_label in zip(queries, labels):\n",
    "    response, total_tokens = decide_task_nature(query, simplified = True)\n",
    "    label = response\n",
    "    if label == correct_label:\n",
    "        label = \"\\033[32m\" + label + \"\\033[0m\" \n",
    "    else:\n",
    "        label = \"\\033[31m\" + label + \"\\033[0m\"\n",
    "    if total_tokens > 170:\n",
    "        total_tokens = \"\\033[31m\"  + str(total_tokens) + \"\\033[0m\"\n",
    "    else:\n",
    "        total_tokens = \"\\033[32m\"  + str(total_tokens) + \"\\033[0m\"\n",
    "    print(f\"Query: {query} Label Predicted: {label}. Correct Label: {correct_label} Total Tokens: {total_tokens}\")\n",
    "    print('='*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a3124d-3ace-4206-8607-a2757d88a033",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2c2319c6-20bc-40d8-9429-526ed8a81c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Give me two sneakers with vibrant colors. Label Predicted: \u001b[32mtechnical\u001b[0m. Correct Label: technical Total Tokens: \u001b[31m244\u001b[0m\n",
      "======================================================================\n",
      "Query: What are the most expensive clothes you have in your catalogue? Label Predicted: \u001b[32mtechnical\u001b[0m. Correct Label: technical Total Tokens: \u001b[31m248\u001b[0m\n",
      "======================================================================\n",
      "Query: I have a green Dress and I like a suggestion on an accessory to match with it. Label Predicted: \u001b[32mcreative\u001b[0m. Correct Label: creative Total Tokens: \u001b[31m254\u001b[0m\n",
      "======================================================================\n",
      "Query: Give me three trousers with vibrant colors you have in your catalogue. Label Predicted: \u001b[32mtechnical\u001b[0m. Correct Label: technical Total Tokens: \u001b[31m249\u001b[0m\n",
      "======================================================================\n",
      "Query: Create a look for a woman walking in a park on a sunny day. It must be fresh due to hot weather. Label Predicted: \u001b[32mcreative\u001b[0m. Correct Label: creative Total Tokens: \u001b[31m260\u001b[0m\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "queries = [\"Give me two sneakers with vibrant colors.\",\n",
    "           \"What are the most expensive clothes you have in your catalogue?\",\n",
    "           \"I have a green Dress and I like a suggestion on an accessory to match with it.\",\n",
    "           \"Give me three trousers with vibrant colors you have in your catalogue.\",\n",
    "           \"Create a look for a woman walking in a park on a sunny day. It must be fresh due to hot weather.\"\n",
    "           ]\n",
    "\n",
    "labels = ['technical', 'technical', 'creative', 'technical', 'creative']\n",
    "\n",
    "for query, correct_label in zip(queries, labels):\n",
    "    response, total_tokens = decide_task_nature(query, simplified = False)\n",
    "    label = response\n",
    "    if label == correct_label:\n",
    "        label = \"\\033[32m\" + label + \"\\033[0m\" \n",
    "    else:\n",
    "        label = \"\\033[31m\" + label + \"\\033[0m\"\n",
    "    if total_tokens > 170:\n",
    "        total_tokens = \"\\033[31m\"  + str(total_tokens) + \"\\033[0m\"\n",
    "    else:\n",
    "        total_tokens = \"\\033[32m\"  + str(total_tokens) + \"\\033[0m\"\n",
    "    print(f\"Query: {query} Label Predicted: {label}. Correct Label: {correct_label} Total Tokens: {total_tokens}\")\n",
    "    print('='*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61efc249-cad7-4bef-a2c9-bda0591e1691",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20857e9-dbd3-4e38-8bec-019718eb3d1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a4ad485-5af2-4730-b750-4cad6ffa9101",
   "metadata": {},
   "source": [
    "## Retrieving the parameters for a given task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ed4f0b86-29b1-4331-8401-8b8ad173e10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tracer.tool\n",
    "def get_params_for_task(task):\n",
    "    \"\"\"\n",
    "    Retrieves specific language model parameters based on the task nature.\n",
    "\n",
    "    This function provides parameter sets tailored for creative or technical tasks to optimize\n",
    "    language model behavior. For creative tasks, higher randomness is encouraged, while technical\n",
    "    tasks are handled with more focus and precision. A default parameter set is provided for unexpected cases.\n",
    "\n",
    "    Parameters:\n",
    "    - task (str): The nature of the task ('creative' or 'technical').\n",
    "\n",
    "    Returns:\n",
    "    - dict: A dictionary containing 'top_p' and 'temperature' settings for the specified task.\n",
    "    \"\"\"\n",
    "    # Create the parameters dict for technical and creative tasks\n",
    "    PARAMETERS_DICT = {\"creative\": {'top_p': 0.9, 'temperature': 1},\n",
    "                       \"technical\": {'top_p': 0.7, 'temperature': 0.3}} \n",
    "    \n",
    "    # If task is technical, return the value for the key technical in PARAMETERS_DICT\n",
    "    if task == 'technical':\n",
    "        param_dict = PARAMETERS_DICT['technical'] \n",
    "\n",
    "    # If task is creative, return the value for the key creative in PARAMETERS_DICT\n",
    "    if task == 'creative':\n",
    "        param_dict = PARAMETERS_DICT['creative'] \n",
    "\n",
    "    # If task is a different value, fallback to another set of parameters\n",
    "    else: # Fallback to a standard value\n",
    "        param_dict = {'top_p': 0.5, 'temperature': 1} \n",
    "\n",
    "    return param_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1eddeea-7b17-44b6-ba5b-3e9feedaf292",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9468251-8e59-42e4-87a8-52c7b143de06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37f08ca2-d1d3-419b-869e-7967e439c2f5",
   "metadata": {},
   "source": [
    "## Retrieving Items Based on Metadata from a Query\n",
    "\n",
    "When a query is identified as a product query, we need to find and return relevant products from the vector database. This process works in three main steps:\n",
    "\n",
    "1. **Generate a metadata JSON** ‚Äî Use the LLM to guess likely values for some product categories based on the query.\n",
    "2. **Run a semantic search** ‚Äî Use those values as filters when querying the database.\n",
    "3. **Return the results** ‚Äî Provide the most relevant products found.\n",
    "\n",
    "The metadata should include values for the following features:\n",
    "\n",
    "* Gender\n",
    "* Master Category\n",
    "* Article Type\n",
    "* Base Color\n",
    "* Season\n",
    "* Usage\n",
    "\n",
    "These categories offer a good trade-off between being specific enough to improve relevance and general enough to avoid missing results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e4aaa0d3-c4f4-4238-adcd-1da44c610c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gender': 'Men',\n",
       " 'masterCategory': 'Apparel',\n",
       " 'subCategory': 'Topwear',\n",
       " 'articleType': 'Shirts',\n",
       " 'baseColour': 'Navy Blue',\n",
       " 'season': 'Fall',\n",
       " 'year': 2011,\n",
       " 'usage': 'Casual',\n",
       " 'productDisplayName': 'Turtle Check Men Navy Blue Shirt',\n",
       " 'price': 67.0,\n",
       " 'product_id': 15970}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's remember the data structure of a product\n",
    "products_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271660f9-977f-4338-bc2f-6d3ad64b03bf",
   "metadata": {},
   "source": [
    "This is a dictionary with every possible value for the categories the LLM can pick from to generate a JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "68a6876b-a4e3-4c25-8f24-51213ce37763",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = {}\n",
    "for d in products_data:\n",
    "    for key, val in d.items():\n",
    "        if key in ('product_id', 'price', 'productDisplayName', 'subCategory', 'year'):\n",
    "            continue\n",
    "        if key not in values.keys():\n",
    "            values[key] = set()\n",
    "        values[key].add(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "12569aab-8093-41bf-9deb-b136b33b14ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'All seasons', 'Fall', 'Spring', 'Summer', 'Winter'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values['season']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858856fe-6a4f-4093-aff9-6cc8cb05d051",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83518d61-4989-4440-81b5-5a659406e5d7",
   "metadata": {},
   "source": [
    "### Generate metadata\n",
    "\n",
    "This function generates a metadata JSON with possible values for each clothing category. The possible values are passed through the dictionary \"values\". "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea0648c-6390-46b8-a777-f53f6990a665",
   "metadata": {},
   "source": [
    "    Note that the prompt is huge. Let's investigate the total tokens for a query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "544636fe-6d0f-45b8-8328-a91bc93de12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_metadata_from_query(query):\n",
    "    \"\"\"\n",
    "    Generates metadata in JSON format based on a given query to filter clothing items.\n",
    "\n",
    "    This function constructs a prompt for a language model to create a JSON object that will\n",
    "    guide the filtering of a vector database query for clothing items. It takes possible values from\n",
    "    a predefined set and ensures only relevant metadata is included in the output JSON.\n",
    "\n",
    "    Parameters:\n",
    "    - query (str): The query describing specific clothing-related needs.\n",
    "\n",
    "    Returns:\n",
    "    - str: A JSON string representing metadata with keys like gender, masterCategory, articleType,\n",
    "      baseColour, price, usage, and season. Each value in the JSON is within a list, with prices specified\n",
    "      as a dict containing \"min\" and \"max\" values. Unrestricted keys should use [\"Any\"] and unspecified\n",
    "      prices should default to {\"min\": 0, \"max\": \"inf\"}.\n",
    "    \"\"\"\n",
    "    \n",
    "    PROMPT = f\"\"\"\n",
    "    A query will be provided. Based on this query, a vector database will be searched to find relevant clothing items.\n",
    "    Generate a JSON object containing useful metadata to filter products for this query.\n",
    "\n",
    "    The possible values for each feature are given in the following JSON:\n",
    "    {values}\n",
    "\n",
    "    Provide a JSON with the features that best fit the query. \n",
    "    Rules:\n",
    "    - Always include these keys: gender, masterCategory, articleType, baseColour, price, usage, season\n",
    "    - Each value must be inside a list (even if there is only one)\n",
    "    - Only use values from the JSON provided above\n",
    "    - If a price range is mentioned, add it under \"price\": {{\"min\": x, \"max\": y}}\n",
    "    - If no price range is given, set price to: {{\"min\": 0, \"max\": \"inf\"}}\n",
    "    - Return only the JSON, nothing else\n",
    "\n",
    "    Example of expected JSON:\n",
    "    {{\n",
    "      \"gender\": [\"Women\"],\n",
    "      \"masterCategory\": [\"Apparel\"],\n",
    "      \"articleType\": [\"Dresses\"],\n",
    "      \"baseColour\": [\"Blue\"],\n",
    "      \"price\": {{\"min\": 0, \"max\": \"inf\"}},\n",
    "      \"usage\": [\"Formal\"],\n",
    "      \"season\": [\"All seasons\"]\n",
    "    }}\n",
    "\n",
    "    Query: {query}\n",
    "    \"\"\"\n",
    "    \n",
    "    with tracer.start_as_current_span(\"generate_metadata_from_query\", openinference_span_kind=\"tool\") as span:\n",
    "        span.set_input(query)\n",
    "        with tracer.start_as_current_span(\"llm_call\", openinference_span_kind=\"llm\") as metadata_span:\n",
    "            # Generate the response with the generate_with_single_input, PROMPT, temperature = 0 (low randomness) and max_tokens = 1500.\n",
    "            kwargs = {\"prompt\": PROMPT, 'temperature': 0, \"max_tokens\": 1500} \n",
    "            metadata_span.set_input(kwargs)\n",
    "            try:\n",
    "                response = generate_with_single_input(**kwargs) \n",
    "            except Exception as error:\n",
    "                metadata_span.record_exception(error)\n",
    "                metadata_span.set_status(Status(StatusCode.ERROR))\n",
    "            else:\n",
    "                # OpenInference Semantic Conventions for computing Costs\n",
    "                metadata_span.set_attribute(\"llm.token_count.prompt\", response['usage']['prompt_tokens'])\n",
    "                metadata_span.set_attribute(\"llm.token_count.completion\", response['usage']['completion_tokens'])\n",
    "                metadata_span.set_attribute(\"llm.token_count.total\", response['usage']['total_tokens'])\n",
    "                metadata_span.set_attribute(\"llm.model_name\", response['model'])\n",
    "                metadata_span.set_attribute(\"llm.provider\", 'together.ai')\n",
    "                metadata_span.set_output(response)\n",
    "                metadata_span.set_status(Status(StatusCode.OK))\n",
    "\n",
    "        # Get the Label by accessing the content key of the response dictionary\n",
    "        content = response['choices'][0]['message']['content']\n",
    "        total_tokens = response['usage']['total_tokens']\n",
    "        span.set_output({\"content\": content, 'total_tokens':total_tokens})\n",
    "        span.set_status(Status(StatusCode.OK))   \n",
    "\n",
    "    \n",
    "    return content, total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "830319fb-fa36-4dac-ab73-2cbe83dd11c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "content, total_tokens = generate_metadata_from_query(\"Create a look for a man that suits a sunny day in the park. I don't want to spend more than 300 dollars on each piece.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "06ccba4d-2602-4def-b31f-b6618ccb9003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1445"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c4237417-3b0f-43e0-8730-0698b6a3e884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"gender\": [\"Men\"],\n",
      "  \"masterCategory\": [\"Apparel\"],\n",
      "  \"articleType\": [\"Tshirts\", \"Shorts\", \"Sunglasses\", \"Shoes\"],\n",
      "  \"baseColour\": [\"Yellow\", \"Navy Blue\", \"Green\", \"Red\"],\n",
      "  \"price\": {\"min\": 0, \"max\": 300},\n",
      "  \"usage\": [\"Casual\", \"Sports\"],\n",
      "  \"season\": [\"Summer\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f6b726-775f-4708-bbfc-f955bec292e0",
   "metadata": {},
   "source": [
    "So far, each product query has involved processing around **1,500 tokens**‚Äîmainly because we generate a set of filters across multiple categories before searching.\n",
    "\n",
    "we will now **simplify** this process.\n",
    "\n",
    "Instead of creating detailed filters for each category (like gender, color, etc.), the system will just use **semantic search directly on the user query**. This means:\n",
    "\n",
    "* No more generating metadata.\n",
    "* Just take the user‚Äôs question and run a semantic search on the product collection.\n",
    "\n",
    "This approach is faster, uses fewer tokens, and is still effective for most queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc64d3f-5d37-4c10-90f3-e691b3350455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "abc0b601-5f6f-4ea9-b716-266dbfc26882",
   "metadata": {},
   "source": [
    "### Loading the Weaviate Product Collection\n",
    "\n",
    "Now it is time to work with the Weaviate collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5277026d-b8d9-48bd-afca-336e66b86b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_collection = client.collections.get('products')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9d399e4b-8c02-4991-a4dd-ab040a30e4da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44423"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(products_collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6124cd5-5d0a-4ab5-9a0b-202c8d3d9347",
   "metadata": {},
   "source": [
    "### Filtering by Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5ab97bc9-2ae2-40ed-b71d-bf704d6b4b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tracer.tool\n",
    "def parse_json_output(llm_output):\n",
    "    try:\n",
    "        # Since the input might be improperly formatted, ensure any single quotes are removed\n",
    "        llm_output = llm_output.replace(\"\\n\", '').replace(\"'\",'').replace(\"}}\", \"}\").replace(\"{{\", \"{\")  # Remove any erroneous structures\n",
    "        \n",
    "        # Attempt to parse JSON directly provided it is a properly-structured JSON string\n",
    "        parsed_json = json.loads(llm_output)\n",
    "        return parsed_json\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSON parsing failed: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b333013e-43c2-44f2-95a3-4a6bc93ce1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tracer.tool\n",
    "def get_filter_by_metadata(json_output: dict):\n",
    "    \"\"\"\n",
    "    Generate a list of Weaviate filters based on a provided metadata dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    - json_output (dict) or None: Dictionary containing metadata keys and their values.\n",
    "\n",
    "    Returns:\n",
    "    - list[Filter] or None: A list of Weaviate filters, or None if input is None.\n",
    "    \"\"\"\n",
    "    # If the input dictionary is None, return None immediately\n",
    "    if json_output is None:\n",
    "        return None\n",
    "\n",
    "    # Define a tuple of valid keys that are allowed for filtering\n",
    "    valid_keys = (\n",
    "        'gender',\n",
    "        'masterCategory',\n",
    "        'articleType',\n",
    "        'baseColour',\n",
    "        'price',\n",
    "        'usage',\n",
    "        'season',\n",
    "    )\n",
    "\n",
    "    # Initialize an empty list to store the filters\n",
    "    filters = []\n",
    "\n",
    "    # Iterate over each key-value pair in the input dictionary\n",
    "    for key, value in json_output.items():\n",
    "        # Skip the key if it is not in the list of valid keys\n",
    "        if key not in valid_keys:\n",
    "            continue\n",
    "\n",
    "        # Special handling for the 'price' key\n",
    "        if key == 'price':\n",
    "            # Ensure the value associated with 'price' is a dictionary\n",
    "            if not isinstance(value, dict):\n",
    "                continue\n",
    "\n",
    "            # Extract the minimum and maximum prices from the dictionary\n",
    "            min_price = value.get('min')\n",
    "            max_price = value.get('max')\n",
    "\n",
    "            # Skip if either min_price or max_price is not provided\n",
    "            if min_price is None or max_price is None:\n",
    "                continue\n",
    "\n",
    "            # Skip if min_price is non-positive or max_price is infinity\n",
    "            if min_price <= 0 or max_price == 'inf':\n",
    "                continue\n",
    "\n",
    "            # Add filters for price greater than min_price and less than max_price\n",
    "            filters.append(Filter.by_property(key).greater_than(min_price))\n",
    "            filters.append(Filter.by_property(key).less_than(max_price))\n",
    "        else:\n",
    "            # For other valid keys, add a filter that checks for any of the provided values\n",
    "            filters.append(Filter.by_property(key).contains_any(value))\n",
    "\n",
    "    return filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e1f27b99-60fa-4f62-b06b-c7a64917a5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tracer.tool\n",
    "def generate_filters_from_query(query):\n",
    "    json_string, total_tokens = generate_metadata_from_query(query)\n",
    "    json_output = parse_json_output(json_string)\n",
    "    filters = get_filter_by_metadata(json_output)\n",
    "    return filters, total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63362b40-683c-438c-a9e9-6e17d30e31f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b92e56ad-a10c-4485-ac1a-66e07d6d44c6",
   "metadata": {},
   "source": [
    "It‚Äôs a modified version of the one we used previously, with one key change:\n",
    "\n",
    "* It now includes a boolean parameter called `simplified`.\n",
    "* If `simplified` is `True`, the function **must skip metadata filtering** and perform a **simple semantic search** using the query.\n",
    "* Choose an appropriate limit‚Äî5 may be too low. In the previous scenario, 20 items were returned, so you might want to stick with that.\n",
    "\n",
    "Therefore, when `simplified = True`, we should only run a semantic search‚Äî**no metadata filters should be applied**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9681e2e2-85f4-4c14-aeb8-2e8c228bdcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_products_from_query(query, simplified = False):\n",
    "    \"\"\"\n",
    "    Retrieve the most relevant products for a given query by applying semantic search and optional filters.\n",
    "\n",
    "    This function generates metadata filters from the query and uses them to search for products \n",
    "    that best match the intended criteria. If `simplified` is True, it performs only a basic semantic \n",
    "    search with no filters. If the filtered search returns too few results, it progressively reduces \n",
    "    filtering constraints based on the predefined importance of each filter.\n",
    "\n",
    "    Parameters:\n",
    "    query (str): The query string used to search for relevant products.\n",
    "    simplified (bool): If True, only a simple semantic search is performed without any metadata filters.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of product objects that are most relevant to the query.\n",
    "    total_tokens: The number of tokens used in the LLM call. Returns 0 if simplified search is used.\n",
    "    \"\"\"\n",
    "    \n",
    "    # If simplified, just do a semantic search with 20 objects and return it\n",
    "    if simplified:\n",
    "        with tracer.start_as_current_span(\"get_relevant_products_from_query\", openinference_span_kind=\"retriever\") as span:  \n",
    "            span.set_input({'query':query, 'simplified':simplified})\n",
    "            \n",
    "            results = products_collection.query.near_text(query, limit=20)\n",
    "\n",
    "            # Set the retrieved documents as attributes on the span\n",
    "            for i, document in enumerate(results.objects): \n",
    "                span.set_attribute(f\"retrieval.documents.{i}.document.id\", str(document.uuid)) \n",
    "                span.set_attribute(f\"retrieval.documents.{i}.document.metadata\", str(document.metadata)) \n",
    "                span.set_attribute( \n",
    "                    f\"retrieval.documents.{i}.document.content\", str(document.properties) #@ KEEP\n",
    "                )  \n",
    "            \n",
    "            span.set_output({\"results\": results.objects, \"total_tokens\": 0})\n",
    "            span.set_status(Status(StatusCode.OK))  \n",
    "    \n",
    "            return results.objects, 0  # Total tokens in this case is 0 because there was no LLM call!\n",
    "            \n",
    "    # If not simplified, perform the previous workflow by generating the filters and then doing a semantic search with them\n",
    "    with tracer.start_as_current_span(\"get_relevant_products_from_query\", openinference_span_kind=\"retriever\") as span:  \n",
    "        span.set_input({'query':query, 'simplified':simplified})\n",
    "        filters, total_tokens = generate_filters_from_query(query)  # Generate filters based on the query\n",
    "\n",
    "    # Check if there are no applicable filters\n",
    "        if filters is None or len(filters) == 0:\n",
    "            span.set_attribute(\"retrieval.filters\", '')\n",
    "            results = products_collection.query.near_text(query, limit=20) \n",
    "            # Set the retrieved documents as attributes on the span\n",
    "            for i, document in enumerate(results.objects): \n",
    "                span.set_attribute(f\"retrieval.documents.{i}.document.id\", str(document.uuid))\n",
    "                span.set_attribute(f\"retrieval.documents.{i}.document.metadata\", str(document.metadata)) \n",
    "                span.set_attribute( \n",
    "                    f\"retrieval.documents.{i}.document.content\", str(document.properties) \n",
    "                )  \n",
    "            span.set_output({\"results\": results.objects, \"total_tokens\": total_tokens})\n",
    "            span.set_status(Status(StatusCode.OK))  \n",
    "            return results.objects, total_tokens\n",
    "            \n",
    "    # Query with filters and limit to the top 20 relevant objects\n",
    "        span.set_attribute(\"retrieval.filters\", str(filters))\n",
    "        results = products_collection.query.near_text(query, filters=Filter.all_of(filters), limit=20)\n",
    "        span.set_attribute(\"retrieval.len\", len(results.objects))\n",
    "        # Set the retrieved documents as attributes on the span\n",
    "        for i, document in enumerate(results.objects): \n",
    "            span.set_attribute(f\"retrieval.documents.{i}.document.id\", str(document.uuid))\n",
    "            span.set_attribute(f\"retrieval.documents.{i}.document.metadata\", str(document.metadata)) \n",
    "            span.set_attribute( \n",
    "                f\"retrieval.documents.{i}.document.content\", str(document.properties) \n",
    "            )\n",
    "    \n",
    "        # If the result set contains fewer than 10 products, try reducing filters to broaden the search\n",
    "        importance_order = [ 'baseColour', 'masterCategory', 'usage', 'masterCategory', 'season', 'articleType', 'gender']\n",
    "        if len(results.objects) < 10:\n",
    "            # Iterate through the importance order of filters\n",
    "            for i in range(len(importance_order)):\n",
    "                with tracer.start_as_current_span(f\"refilter_{i}\", openinference_span_kind=\"chain\") as refilter_span: \n",
    "                    # Create a list of filters that excludes less important ones\n",
    "                    filtered_filters = [x for x in filters if x.target in importance_order[i+1:]]\n",
    "                    refilter_span.set_input(str(filtered_filters))\n",
    "                    \n",
    "                    results = products_collection.query.near_text(query, filters=Filter.all_of(filtered_filters), limit=20)\n",
    "                    # Set the retrieved documents as attributes on the span\n",
    "                    for j, document in enumerate(results.objects): \n",
    "                        refilter_span.set_attribute(f\"retrieval.documents.{j}.document.id\", str(document.uuid))\n",
    "                        refilter_span.set_attribute(f\"retrieval.documents.{j}.document.metadata\", str(document.metadata)) \n",
    "                        refilter_span.set_attribute( \n",
    "                            f\"retrieval.documents.{j}.document.content\", str(document.properties) \n",
    "                        )\n",
    "                    # If sufficient products have been found, return early\n",
    "                    if len(results.objects) >= 5:\n",
    "                        refilter_span.set_output(results.objects)\n",
    "                        refilter_span.set_status(Status(StatusCode.OK))  \n",
    "                        span.set_output(results.objects)\n",
    "                        span.set_status(Status(StatusCode.OK)) \n",
    "                        return results.objects, total_tokens\n",
    "        span.set_output(results.objects)\n",
    "        span.set_status(Status(StatusCode.OK)) \n",
    "        return results.objects, total_tokens  # Return the final set of relevant products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4c9d1fb5-e6f8-494e-b0d4-d703ddda37e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Give me three T-shirts to use in sunny days\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "650bd0ec-cc5a-493d-b6f2-7a7cefe2b64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "t, total_tokens = get_relevant_products_from_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "54d1335f-c47a-42dd-a32f-1801f33d0251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1411"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08531d8-656e-4b63-a8da-858d977f8ba7",
   "metadata": {},
   "source": [
    "Around 1500 tokens for this query! Let's try with the simplified version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "eadb2579-e88d-4efc-8250-188d7bfd6b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "t, total_tokens = get_relevant_products_from_query(query, simplified = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "04ca5aa6-b2a1-4882-91fe-643061d8b55f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7079a9-ded3-4a05-b26f-f46cc512b3cc",
   "metadata": {},
   "source": [
    "Note that this query took 0 tokens, as it didn't use the LLM. It directly used the query to retrieve the objects that are in the vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ddb395-b7d7-4d84-8923-4b4145d4559e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a15c67-a97b-4637-b831-18657b5d6b7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6de1ea81-856d-4926-ae01-d63dc84a479a",
   "metadata": {},
   "source": [
    "## Generating the retrieved items as context\n",
    "\n",
    "Now, for the given retrieved items, let's generate a simple context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "982ffcb5-df0a-43c7-93ea-bcfad858d736",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tracer.tool\n",
    "def generate_items_context(results):\n",
    "    \"\"\"\n",
    "    Compile detailed product information from a list of result objects into a formatted string.\n",
    "\n",
    "    Parameters:\n",
    "    results (list): A list of result objects, each having a `properties` attribute that is a dictionary \n",
    "                    containing product attributes such as 'product_id', 'productDisplayName', \n",
    "                    'masterCategory', 'usage', 'gender', 'articleType', 'subCategory', \n",
    "                    'baseColour', 'season', and 'year'.\n",
    "\n",
    "    Returns:\n",
    "    str: A multi-line string where each line contains the formatted details of a single product.\n",
    "         Each product detail includes the product ID, name, category, usage, gender, type, color, \n",
    "         season, and year.\n",
    "    \"\"\"\n",
    "    t = \"\"  # Initialize an empty string to accumulate product information\n",
    "\n",
    "    for item in results:  # Iterate through each item in the results list\n",
    "        item = item.properties  # Access the properties dictionary of the current item\n",
    "\n",
    "        # Append formatted product details to the output string\n",
    "        t += (\n",
    "            f\"Product ID: {item['product_id']}. \"\n",
    "            f\"Product name: {item['productDisplayName']}. \"\n",
    "            f\"Product Category: {item['masterCategory']}. \"\n",
    "            f\"Product usage: {item['usage']}. \"\n",
    "            f\"Product gender: {item['gender']}. \"\n",
    "            f\"Product Type: {item['articleType']}. \"\n",
    "            f\"Product Category: {item['subCategory']} \"\n",
    "            f\"Product Color: {item['baseColour']}. \"\n",
    "            f\"Product Season: {item['season']}. \"\n",
    "            f\"Product Year: {item['year']}.\\n\"\n",
    "        )\n",
    "\n",
    "    return t  # Return the complete formatted string with product details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e357a1b6-54c3-4347-9b62-1592d5c609e3",
   "metadata": {},
   "source": [
    "### Query on Products\n",
    "\n",
    "The next function will answer a product query. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "436286cd-93a4-4107-9f9b-4a7ca4fc3b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tracer.tool\n",
    "def query_on_products(query, simplified = False):\n",
    "    \"\"\"\n",
    "    Execute a product query process to generate a response based on the nature of the query.\n",
    "\n",
    "    Parameters:\n",
    "    query (str): The input query string that needs to be analyzed and answered using product data.\n",
    "    task_nature_prompt_function (func): The prompt function to be used to decide the task nature (if creative of technical)\n",
    "    simplified (bool): If True, does not use LLM to generate metadata for filtering\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary of keyword arguments (`kwargs`) containing the prompt and additional settings \n",
    "          for creating a response, suitable for input to an LLM or other processing system.\n",
    "    int: Number of tokens used in the process to create the kwargs dictionary\n",
    "\n",
    "    Outputs:\n",
    "    str: The content of the generated response from the LLM based on the provided query and product \n",
    "         information.\n",
    "    \"\"\"\n",
    "    total_tokens = 0\n",
    "    # Determine if the query is technical or creative in nature\n",
    "    \n",
    "    query_label, tokens = decide_task_nature(query, simplified = simplified)\n",
    "    \n",
    "    # Sum the tokens used to decide the task nature (creative or technical)\n",
    "    total_tokens += tokens\n",
    "\n",
    "    # Obtain necessary parameters based on the query type\n",
    "    parameters_dict = get_params_for_task(query_label)\n",
    "    \n",
    "    # Retrieve products that are relevant to the query\n",
    "    relevant_products, tokens = get_relevant_products_from_query(query, simplified = simplified)\n",
    "    \n",
    "    # Sum the tokens used to get relevant products \n",
    "    total_tokens += tokens\n",
    "     \n",
    "    # Create a context string from the relevant products\n",
    "    context = generate_items_context(relevant_products)\n",
    "\n",
    "    # Construct a prompt including product details and the query. Remember to add the context and the query in the prompt, also, ask the LLM to provide the product ID in the answer\n",
    "    PROMPT = (\n",
    "    f\"You are a helpful shopping assistant. Answer the user‚Äôs query in a natural conversational style. \"\n",
    "    f\"You are a very helpful assistant. You are given a list of clothing products. Answer the query below by selecting the most relevant items. \"\n",
    "    f\"Always include the item ID in your response. \"\n",
    "    f\"Only describe features that are directly relevant to the query‚Äîkeep descriptions concise. \"\n",
    "    f\"If the query does not specify a number of products, return at most five. \"\n",
    "    f\"\\n\\nAVAILABLE PRODUCTS:\\n{context}\\n\\nQUERY:\\n{query}\"\n",
    ")\n",
    "    \n",
    "    # Generate kwargs (parameters dict) for parameterized input to the LLM with , Prompt, role = 'assistant' and **parameters_dict\n",
    "    kwargs = generate_params_dict(PROMPT, role='assistant', **parameters_dict) \n",
    "    \n",
    "    return kwargs, total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb63b4a2-e82d-46a4-a8aa-5f31374858aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9262ac75-6021-4be7-a78a-9c6b5368b643",
   "metadata": {},
   "source": [
    "Let's check with both the previous setup and the enhanced setup\n",
    "\n",
    "\n",
    "#### Previous setup with simplified = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d28b42c1-aa24-4a58-931b-2b7ecdb67adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs, total_tokens = query_on_products('Make a wonderful look for a man attending a wedding party happening during night.', simplified = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a73d0869-326c-4270-8018-d8f131f6c650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on your query, I would recommend the following products to create a wonderful look for a man attending a wedding party at night:\n",
      "\n",
      "1. Product ID: 12347 - Fastrack Men Red Manhattan Regular Fit Solid Formal Shirt (to add a pop of color and create a stylish look)\n",
      "2. Product ID: 19860 - U.S. Polo Assn. Men Solid Olive Jacket (to add a touch of sophistication and blend with the wedding party atmosphere)\n",
      "3. Product ID: 19855 - U.S. Polo Assn. Men Solid Navy Blue Jackets (to add a touch of elegance and complement the red shirt)\n",
      "4. Product ID: 17150 - U.S. Polo Assn. Men Solid Red Jacket (not recommended as it might be too casual and overpowering)\n",
      "5. Product ID: 59106 - Just Natural Men Black Jacket (not recommended as it might not add enough style and elegance to the outfit)\n",
      "\n",
      "These products will create a well-coordinated and stylish outfit for a man attending a wedding party at night.\n"
     ]
    }
   ],
   "source": [
    "result = generate_with_single_input(**kwargs)\n",
    "print(result['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af5abd4-08cf-4fe7-90ef-cae51a778ac8",
   "metadata": {},
   "source": [
    "Now let's sum the total tokens to generate the kwargs dictionary and the total tokens used in the final execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b74fc8d5-a9d0-41cc-b0a8-1de7e9e07ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens used in the query is: 2556\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total tokens used in the query is: {total_tokens + result['usage']['total_tokens']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923b2908-11d5-4ee0-9e86-a3c84e2090e0",
   "metadata": {},
   "source": [
    "**New setup with <code>simplified = True</code>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6b37df46-82ee-4abe-81c5-c1731ec1a2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs, total_tokens = query_on_products('Make a wonderful look for a man attending a wedding party happening during night.', simplified = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e1c56d2b-cb78-45d4-8172-298b77969e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "41e64b52-437a-4429-b28a-09137f24f177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on your query, I recommend the following products to create a wonderful look for a man attending a wedding party during night:\n",
      "\n",
      "1. Product ID: 8960 - Provogue Men Night Black Shoe\n",
      "This shoe is perfect for a formal night event like a wedding party. Its black color and formal design will complement any outfit.\n",
      "\n",
      "2. Product ID: 17375, Product ID: 17378, Product ID: 17370, Product ID: 17361, Product ID: 17374, Product ID: 17359, Product ID: 17373, Product ID: 17369, Product ID: 17377 - Arrow Men Formal Purple Tie+Cufflink+Pocket square - Combo Pack (any one)\n",
      "Purple is a classic and elegant color for a wedding party, and the combo pack includes a tie, cufflink, and pocket square. This will add a touch of sophistication to the outfit.\n",
      "\n",
      "3. Product ID: 40245, Product ID: 40216 - Provogue Men Pink Tie (any one)\n",
      "If the wedding party has a more casual or unique theme, a pink tie could be a bold and eye-catching choice. Pair it with the black shoe and purple combo pack for a stylish and memorable look.\n",
      "\n",
      "These products will help create a wonderful and stylish outfit for a man attending a wedding party during night.\n"
     ]
    }
   ],
   "source": [
    "result = generate_with_single_input(**kwargs)\n",
    "print(result['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "58d491d5-b637-43b7-935d-4861111c5618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens used in the query is: 1906\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total tokens used in the query is: {total_tokens + result['usage']['total_tokens']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b557fdb-3106-4168-9285-acb145462762",
   "metadata": {},
   "source": [
    "And the total tokens used in one query was way lower than before!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f380a3b-bbd0-44f9-8954-14ca72132ea6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac428d5f-2378-4b91-942a-14949606d8a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9cb2d90-9c74-47a1-b515-0b27920f7721",
   "metadata": {},
   "source": [
    "## The final function! \n",
    "\n",
    "### The function to rule them all\n",
    "\n",
    "Now let's consolidate the functions\n",
    "\n",
    "The function will:\n",
    "\n",
    "1. Check if the query is FAQ or Product\n",
    "2. If FAQ, runs the FAQ related workflow\n",
    "3. If Product, runs the Product related workflow\n",
    "4. Add the information into a dataframe\n",
    "\n",
    "It returns the kwargs dict with the appropriate arguments and the total tokens used to get to the kwargs dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "df3cee6c-a8bc-40e2-b6c8-caa435547072",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tracer.tool\n",
    "def answer_query(query, model = \"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\", simplified=False):\n",
    "    \"\"\"\n",
    "    Processes a user's query to determine its type (FAQ or Product) and executes the appropriate workflow.\n",
    "    \n",
    "    Parameters:\n",
    "    - query (str): The query string provided by the user.\n",
    "    - model (str): The model that will answer the question. Defaults to meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo'\n",
    "    - simplified (bool): If True, uses a simplified version of the method. Defaults to False.\n",
    "    \n",
    "    Returns:\n",
    "    - dict: A dictionary containing keyword arguments for further processing.\n",
    "      If the query is neither FAQ nor Product-related, returns a default response dictionary instructing\n",
    "      the assistant to answer based on existing context.\n",
    "    \"\"\"\n",
    "    # Initialize the total tokens used to zero\n",
    "    total_tokens = 0\n",
    "    \n",
    "    # Determine if the query is FAQ or Product and get the token count for this step\n",
    "    label, tokens = check_if_faq_or_product(query, simplified=simplified)\n",
    "    \n",
    "    # Sum the tokens\n",
    "    total_tokens += tokens\n",
    "    \n",
    "    # If the query is neither FAQ nor Product, return a default response\n",
    "    if label not in ['FAQ', 'Product']:\n",
    "        return {\n",
    "            \"role\": \"assistant\",\n",
    "            \"prompt\": (f\"User provided a question that does not fit FAQ or Product-related categories. \"\n",
    "                       f\"Answer it based on the context you already have. Query provided by the user: {query}\")\n",
    "        }\n",
    "    \n",
    "    # Process the query based on its label\n",
    "    if label == 'FAQ':\n",
    "        # Handle FAQ-related queries\n",
    "        kwargs = query_on_faq(query, simplified=simplified)\n",
    "    elif label == 'Product':\n",
    "        try:\n",
    "            # Handle Product-related queries, with error handling in place\n",
    "            kwargs, tokens = query_on_products(query, simplified=simplified)\n",
    "            # Add the tokens to the total tokens\n",
    "            total_tokens += tokens\n",
    "        except Exception:\n",
    "            # Return an error response if an exception occurs during querying\n",
    "            return {\n",
    "                \"role\": \"assistant\",\n",
    "                \"prompt\": (f\"User provided a question that broke the querying system. \"\n",
    "                           f\"Instruct them to rephrase it. Answer it based on the context you already have. \"\n",
    "                           f\"Query provided by the user: {query}\")\n",
    "            }, total_tokens\n",
    "    # Set the model to answer the final query - usually a better one         \n",
    "    kwargs['model'] = model\n",
    "    # Return the kwargs and total_tokens for further processing\n",
    "    return kwargs, total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0edfb758-3b58-4d20-91f8-0b853e93dae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs, total_tokens = answer_query(\"Give me three examples of blue t-shirts available on your catalogue.\", simplified = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cc86613c-5178-49f7-8913-5a2ae5fc0530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are three blue t-shirts available on our catalogue:\n",
      "\n",
      "1. Product ID: 1847. Product name: Inkfruit Mens Messy T-shirt. Product Color: Blue.\n",
      "2. Product ID: 3103. Product name: Probase Men's Wtf Blue T-Shirt. Product Color: Navy Blue.\n",
      "3. Product ID: 3754. Product name: Status Quo Men's Music Revolution Blue T-shirt. Product Color: Blue.\n",
      "\n",
      "These t-shirts are all blue in color and suitable for casual wear.\n"
     ]
    }
   ],
   "source": [
    "result = generate_with_single_input(**kwargs)\n",
    "print(result['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ab733570-3d48-496b-945f-94b86d0d4ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3462"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get the total tokens for the call, we must sum the total_tokens to get the kwargs dictionary + total tokens from the LLM call\n",
    "total_tokens +  result['usage']['total_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ee8d70-e4ed-49f4-8470-44074c84bfe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "95140b04-eb05-442c-897c-d57d5806f0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs, total_tokens = answer_query(\"Give me three examples of blue t-shirts available on your catalogue.\", simplified = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3fefae6a-4b2e-4fb8-ad5f-c831923acd8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are three blue t-shirts available in our catalogue:\n",
      "\n",
      "1. Product ID: 1847. Product name: Inkfruit Mens Messy T-shirt. Product Color: Blue.\n",
      "2. Product ID: 3995. Product name: Mr.Men Men's Thats Funny Blue T-shirt. Product Color: Blue.\n",
      "3. Product ID: 3103. Product name: Probase Men's Wtf Blue T-Shirt. Product Color: Navy Blue.\n",
      "\n",
      "These are just a few examples of the many blue t-shirts available in our catalogue.\n"
     ]
    }
   ],
   "source": [
    "result = generate_with_single_input(**kwargs)\n",
    "print(result['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b999d8c5-1bf7-4046-8e1f-cf2d75036d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1808"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_tokens +  result['usage']['total_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1451ef3e-9917-4585-b24c-510af87c034b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57848c02-4962-4909-a2f1-79264c6dfa30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b067d640-5adb-4dbb-9fd5-6788ea930039",
   "metadata": {},
   "source": [
    "## The ChatBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "46a48621-09ff-4f99-a137-b3c5b54b7ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "409a82114a4d476ebe35c7c66561f9b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=''), HBox(), HBox(children=(Text(value='', layout=Layout(width='90%'), placeholder='‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chat_widget_standard = ChatWidget(generator_function = lambda x: answer_query(x, simplified = False), tracer = tracer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "597c8138-33f9-4362-9fba-f3b6940934df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mFOLLOW THIS URL TO OPEN THE UI: http://rpyqcvlvppro.labs.coursera.org\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "make_url()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab41e24-3ede-41c5-98e0-9b522a63823f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fec7f1-5adf-4ed5-b085-d6da32dd2f54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
